# redis集群

- redis集群是redis提供的分布式数据库方案，集群通过分片来进行数据共享，并提供复制和故障转移功能。

- redis集群是各个独立的redis服务器，变成集群就需要把这些服务器都连接起来，服务器A向服务器B发送CLUSTER MEET命令会把B加到自己的集群中。

- redis服务器会根据cluster-enabled配置选项是否为yes来决定是否开启服务器集群模式。服务器会继续使用单机redis服务器的组件，集群下使用clusterNode，clusterLink，clusterState结构来保存数据。

- clusterNode节点代码如下

```cpp
typedef struct clusterNode {
    mstime_t ctime; /* Node object creation time. 节点的创建时间*/

    //节点名字，40个十六进制字符组成
    char name[CLUSTER_NAMELEN]; /* Node name, hex string, sha1-size， */

    //节点标识，记录节点的角色（主节点从节点），和节点的状态（是否在线）
    int flags;      /* CLUSTER_NODE_... */

    //配置纪元，用于故障转移
    uint64_t configEpoch; /* Last configEpoch observed for this node */

    //下面两个记录了节点负责处理哪些槽
    unsigned char slots[CLUSTER_SLOTS/8]; /* slots handled by this node */
    int numslots;   /* Number of slots handled by this node */

    int numslaves;  /* Number of slave nodes, if this is a master */
    struct clusterNode **slaves; /* pointers to slave nodes */
    struct clusterNode *slaveof; /* pointer to the master node. Note that it
                                    may be NULL even if the node is a slave
                                    if we don't have the master node in our
                                    tables. */
    mstime_t ping_sent;      /* Unix time we sent latest ping */
    mstime_t pong_received;  /* Unix time we received the pong */
    mstime_t fail_time;      /* Unix time when FAIL flag was set */
    mstime_t voted_time;     /* Last time we voted for a slave of this master */
    mstime_t repl_offset_time;  /* Unix time we received offset for this node */
    mstime_t orphaned_time;     /* Starting time of orphaned master condition */
    long long repl_offset;      /* Last known repl offset for this node. */

    //节点的ip地址
    char ip[NET_IP_STR_LEN];  /* Latest known IP address of this node */
    
    //节点的端口号
    int port;                   /* Latest known clients port of this node */
    int cport;                  /* Latest known cluster port of this node. */

    //保存链接节点的信息
    clusterLink *link;          /* TCP/IP link with this node */
    list *fail_reports;         /* List of nodes signaling this as failing */
} clusterNode;

```

里面得clusterLink保存了连接节点的有关信息。结构如下

```cpp
typedef struct clusterLink {
    //连接创建的时间
    mstime_t ctime;             /* Link creation time */

    //连接的socket描述符
    int fd;                     /* TCP socket file descriptor */

    //输出缓冲区
    sds sndbuf;                 /* Packet send buffer */

    //输入缓冲区
    sds rcvbuf;                 /* Packet reception buffer */

    //与该节点关联的节点
    struct clusterNode *node;   /* Node related to this link if any, or NULL */
} clusterLink;
```

另外每个节点使用clusterState保存当前它所在集群的状态，结构如下。

```cpp
typedef struct clusterState {
    clusterNode *myself;  /* This node */

    //整个集群的配置纪元
    uint64_t currentEpoch;
    //集群的状态
    int state;            /* CLUSTER_OK, CLUSTER_FAIL, ... */
    //集群中节点的数量
    int size;             /* Num of master nodes with at least one slot */
    //集群节点名单，键为节点名字，值为节点的clusterNode结构。
    dict *nodes;          /* Hash table of name -> clusterNode structures */
    dict *nodes_black_list; /* Nodes we don't re-add for a few seconds. */
    clusterNode *migrating_slots_to[CLUSTER_SLOTS];
    clusterNode *importing_slots_from[CLUSTER_SLOTS];
    clusterNode *slots[CLUSTER_SLOTS];
    uint64_t slots_keys_count[CLUSTER_SLOTS];
    rax *slots_to_keys;
    /* The following fields are used to take the slave state on elections. */
    mstime_t failover_auth_time; /* Time of previous or next election. */
    int failover_auth_count;    /* Number of votes received so far. */
    int failover_auth_sent;     /* True if we already asked for votes. */
    int failover_auth_rank;     /* This slave rank for current auth request. */
    uint64_t failover_auth_epoch; /* Epoch of the current election. */
    int cant_failover_reason;   /* Why a slave is currently not able to
                                   failover. See the CANT_FAILOVER_* macros. */
    /* Manual failover state in common. */
    mstime_t mf_end;            /* Manual failover time limit (ms unixtime).
                                   It is zero if there is no MF in progress. */
    /* Manual failover state of master. */
    clusterNode *mf_slave;      /* Slave performing the manual failover. */
    /* Manual failover state of slave. */
    long long mf_master_offset; /* Master offset the slave needs to start MF
                                   or zero if stil not received. */
    int mf_can_start;           /* If non-zero signal that the manual failover
                                   can start requesting masters vote. */
    /* The followign fields are used by masters to take state on elections. */
    uint64_t lastVoteEpoch;     /* Epoch of the last vote granted. */
    int todo_before_sleep; /* Things to do in clusterBeforeSleep(). */
    /* Messages received and sent by type. */
    long long stats_bus_messages_sent[CLUSTERMSG_TYPE_COUNT];
    long long stats_bus_messages_received[CLUSTERMSG_TYPE_COUNT];
    long long stats_pfail_nodes;    /* Number of nodes in PFAIL status,
                                       excluding nodes without address. */
} clusterState;
```

- 两个节点建立连接后会把双方的信息用新的clusterNode结构来保存，并更新clusterState结构，之后，收到链接命令的集群中的节点会把刚刚连接到集群中的节点广播给其他节点。

- redis集群通过分片的方式来保存数据库中的键值对，集群中的数据库被分为16384个槽，数据库中的每一个键都在这些槽中，集群中的每个节点可以运行0-16384个槽。当一个集群中所有的16384个槽都在处理时，集群处于上线状态，否则，集群处于下线状态。上面的clusterNode结构里有记录当前节点处理哪些槽。

- slots是个二进制数组，CLUSTER_SLOTS是个宏大小就是16384，char[16384/8]刚好是16384个字节。如果当前节点需要处理哪个槽，就把该位置置为1，其实就是一个哈希位图。numslots为该节点总的处理数量。一个节点在设置了slots后会通知集群中的其他节点告知自己已经将哪些设置为处理。

- clusterState里的 clusterNode *slots[CLUSTER_SLOTS]结构，用来记录该集群中每一个槽分配的节点，如果某一个指向了null代表的就是该槽尚未分配。

- clusterNode里的slots只记录了当前的节点保存的指派信息，clusterState里的slots记录了整个集群的指派信息。添加某节点处理槽代码如下。

```cpp
int clusterAddSlot(clusterNode *n, int slot) {
    if (server.cluster->slots[slot]) return C_ERR;
    clusterNodeSetSlotBit(n,slot);
    server.cluster->slots[slot] = n;
    return C_OK;
}
int clusterNodeSetSlotBit(clusterNode *n, int slot) {
    int old = bitmapTestBit(n->slots,slot);
    bitmapSetBit(n->slots,slot);
    if (!old) {
        n->numslots++;
        if (n->numslots == 1 && clusterMastersHaveSlaves())
            n->flags |= CLUSTER_NODE_MIGRATE_TO;
    }
    return old;
}
```

- 集群的某个服务器节点接收到命令之后，首先检查自己的槽，看看是否是指派给自己的，否则返回一个错误，将客户端指引到正确的节点，并在此发送命令。

- 一个键传进来使用CRC16算法计算出来的值&16383就是当前的键应当放在哪个槽里。

- 集群保存键值对的方式与单机数据库相同，区别是，节点只能使用0号数据库，节点会用clusterState结构里的slots_to_keys跳跃表来保存槽和键之间的关系。这个结构是个跳跃表，节点的分值就是槽号，节点的成员就是数据库键。

- 重新分片，就是将任意数量已经指派给某个节点的槽改成指派给那另一个节点。重新分片操作可以在线执行，无需集群下线。

- 在重新分片的过程中，其实是将原节点槽中的键一个一个转移到另一个节点的里，之后转移完成会对集群里所有节点广播，在对键进行操作的时候，可能正在转移的过程中，所以步骤是先去原节点槽里去找有没有该键，如果没有，返回一个ASK错误给客户端，将客户端的命令转向目标节点，客户端再向目标节点发送命令。

- clusterState结构里的importing_slots_from这个结构记录了当前节点正在从其他节点导入的槽，是个clusterNode数组，如果clusterNode[i]不为空指向一个clusterNode结构，代表指向的该节点正在向槽i导入。之后里面的migrating_slots_to的功能正好与之相反，记录了当前节点向外导出。

- ask命令就是现在自己的数据库里找发送操作命令的键，没找到的话就去migrating_slots_to里找，如果还没找到就发送ask。

- moved也是转移客户端命令，区别是moved其实是去另一个节点找，槽并不是在转移的过程，而ask是在转移的过程，一种临时的措施，命令只会在ask后去另一个节点找一次。

- 复制和故障转移，redis集群中的节点分为主节点和从节点，主节点用于处理槽，而从节点则用于复制某个主节点（参考前一章复制），并在被复制的节点下线时，代替下线节点继续处理命令请求。当主节点下线后，从节点接替主节点的槽，成为主节点，之后如果之前的主节点上线后，成为当前主节点的从节点。

- slaveof里指向的就是当前节点正在复制的主节点，当一个节点成为从节点后，会把消息发给集群中的没一个节点，让所有节点知晓，slaves结构记录了当前节点的从节点，numslaves记录了当前节点的从节点的数量。

- 集群中的每个节点都会定期向其他节点发送ping消息，以此来检测对方是否在线，如果接受ping消息的节点没有在规定时间内返回，那么发送节点就会把接受节点设置为疑似下线节点。当一个主节点A得知主节点B已经将C设置为下线状态那么，A会在自己的clusterState得nodes里找到B节点并将下线信息添加到fail_reports里面，一个保存了疑似下线节点的列表，里面的结构如下。如果一个集群里面，半数以上的主节点都将某个主节点X报告为疑似下线，那么这个主节点将被标记为下线，将改节点标记为下线得节点会把这个消息告知所有主节点，之后所有主节点也会标记下线。之后会进行故障转移，故障转移得过程和节点复制里的故障转移是一样的，具体可以参考之前的复制那节。

```cpp
typedef struct clusterNodeFailReport {
    struct clusterNode *node;  /* Node reporting the failure condition. 报告目标节点已经下线的节点*/

    //最后一次从node节点收到下线报告的时间
    //用这个时间戳检查下线报告是否过期
    mstime_t time;             /* Time of the last report from this node. */
} clusterNodeFailReport;
```

- 集群服务器，即节点之间的通讯消息如下

```cpp
//消息头
typedef struct {
    char sig[4];        /* Signature "RCmb" (Redis Cluster message bus). */
    //消息长度
    uint32_t totlen;    /* Total length of this message */
    uint16_t ver;       /* Protocol version, currently set to 1. */
    uint16_t port;      /* TCP base port number. */
    //消息类型
    uint16_t type;      /* Message type */
    //消息正文包含的节点数量
    uint16_t count;     /* Only used for some kind of messages. */
    //发送者所处的配置纪元
    uint64_t currentEpoch;  /* The epoch accordingly to the sending node. */
    //主节点为发送者配置纪元，从节点为正在复制的主节点的配置纪元
    uint64_t configEpoch;   /* The config epoch if it's a master, or the last
                               epoch advertised by its master if it is a
                               slave. */
    uint64_t offset;    /* Master replication offset if node is a master or
                           processed replication offset if node is a slave. */
    //发送者名字
    char sender[CLUSTER_NAMELEN]; /* Name of the sender node */
    //发送者槽信息
    unsigned char myslots[CLUSTER_SLOTS/8];
    //发送者正在复制的主节点的名字
    char slaveof[CLUSTER_NAMELEN];
    char myip[NET_IP_STR_LEN];    /* Sender IP, if not all zeroed. */
    char notused1[34];  /* 34 bytes reserved for future usage. */
    uint16_t cport;      /* Sender TCP cluster bus port */
    uint16_t flags;      /* Sender node flags */
    //集群状态
    unsigned char state; /* Cluster state from the POV of the sender */
    unsigned char mflags[3]; /* Message flags: CLUSTERMSG_FLAG[012]_... */
    // 消息正文
    union clusterMsgData data;
} clusterMsg;


//消息正文
union clusterMsgData {
    /* PING, MEET and PONG */
    struct {
        /* Array of N clusterMsgDataGossip structures */
        clusterMsgDataGossip gossip[1];
    } ping;

    /* FAIL */
    struct {
        clusterMsgDataFail about;
    } fail;

    /* PUBLISH */
    struct {
        clusterMsgDataPublish msg;
    } publish;

    /* UPDATE */
    struct {
        clusterMsgDataUpdate nodecfg;
    } update;

    /* MODULE */
    struct {
        clusterMsgModule msg;
    } module;
};
```

